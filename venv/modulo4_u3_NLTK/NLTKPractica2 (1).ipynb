{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigramas: 87.65970871234029\n",
      "Acierto con bigramas: 89.42636311057363\n",
      "Acierto con trigramas: 89.01624691098375\n",
      "Acierto con HMMs: 89.88905831011094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Importamos el corpus CESS del español, que es una colección de textos anotados\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "\n",
    "# 2. Cargamos todas las frases anotadas del corpus CESS\n",
    "sents = cess_esp.tagged_sents()\n",
    "\n",
    "\n",
    "# 3. Creamos un conjunto de entrenamiento y otro de prueba\n",
    "#Metemos en el conjunto de entrenamiento el 90% de las frases, y el restante 10% en el conjunto de test\n",
    "training = []\n",
    "test = []\n",
    "for i in range(len(sents)):\n",
    "    if i % 10:\n",
    "        training.append(sents[i])\n",
    "    else:\n",
    "        test.append(sents[i])\n",
    "        \n",
    "        \n",
    "# 4. Creamos cuatro tipos distintos de analizadores morfológicos: \n",
    "# - Un tagger basado en unigramas: aprende de la estadística de cada palabra encontrada en el corpus CESS\n",
    "# - Otro basadoen bigramas: aprende de la estadística de una palabra y su palabra anterior\n",
    "# - Otro basado en trigramas: aprende a taggear una palabra basandose en la estadistica de la palabra y sus 2 anteriores\n",
    "# - Otro basado en Modelos Ocultos de Markov (en inglés Hidden Markov Models, HMM): es el modelo mas completo\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "unigram_tagger = UnigramTagger(training)\n",
    "bigram_tagger = BigramTagger(training, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(training, backoff=unigram_tagger)\n",
    "hmm_tagger = HiddenMarkovModelTagger.train(training)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Evaluamos sobre el conjunto de test que no usamos para el entrenamiento, para ver qué porcentaje de acierto hemos conseguido\n",
    "print ('Acierto con unigramas:',unigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con bigramas:',bigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con trigramas:',trigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con HMMs:',hmm_tagger.evaluate(test)*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Los', 'da0mp0'), ('perros', 'ncmp000'), ('son', 'vsip3p0'), ('buenos', 'aq0mp0'), ('chuchetes', None)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Probamos uno de nuestro taggers\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "sentence = \"Los perros son buenos chuchetes\"\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged = trigram_tagger.tag(tokens)\n",
    "\n",
    "\n",
    "print (tagged)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importamos el corpus CESS del español, que es una colección de textos anotados\n",
    "import nltk\n",
    "from nltk.corpus import cess_esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')], ...]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Cargamos todas las frases anotadas del corpus CESS\n",
    "sents = cess_esp.tagged_sents()\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Creamos un conjunto de entrenamiento y otro de prueba\n",
    "#Metemos en el conjunto de entrenamiento el 90% de las frases, y el restante 10% en el conjunto de test\n",
    "training = []\n",
    "test = []\n",
    "for i in range(len(sents)):\n",
    "    if i % 10:\n",
    "        training.append(sents[i])\n",
    "    else:\n",
    "        test.append(sents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# 4. Creamos cuatro tipos distintos de analizadores morfológicos: \n",
    "# - Un tagger basado en unigramas: aprende de la estadística de cada palabra encontrada en el corpus CESS\n",
    "# - Otro basadoen bigramas: aprende de la estadística de una palabra y su palabra anterior\n",
    "# - Otro basado en trigramas: aprende a taggear una palabra basandose en la estadistica de la palabra y sus 2 anteriores\n",
    "# - Otro basado en Modelos Ocultos de Markov (en inglés Hidden Markov Models, HMM): es el modelo mas completo\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigramas: 87.65970871234029\n",
      "Acierto con bigramas: 89.42636311057363\n",
      "Acierto con trigramas: 89.01624691098375\n",
      "Acierto con HMMs: 89.88905831011094\n"
     ]
    }
   ],
   "source": [
    "unigram_tagger = UnigramTagger(training)\n",
    "bigram_tagger = BigramTagger(training, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(training, backoff=unigram_tagger)\n",
    "hmm_tagger = HiddenMarkovModelTagger.train(training)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Evaluamos sobre el conjunto de test que no usamos para el entrenamiento, para ver qué porcentaje de acierto hemos conseguido\n",
    "print ('Acierto con unigramas:',unigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con bigramas:',bigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con trigramas:',trigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con HMMs:',hmm_tagger.evaluate(test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UnigramTagger: size=24060>\n"
     ]
    }
   ],
   "source": [
    "print(unigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
